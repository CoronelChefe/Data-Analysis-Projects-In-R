mutate(perc_survived = (survivors/N)*100, digits = 5)
titanic %>%
select(Survived, Pclass, Age, Sex) %>%
filter(!is.na(Age)) %>%
mutate(agecat = cut(Age, breaks = c(0, 14.99, 50, 150),
include.lowest = TRUE,
labels = c("Under 15", "15 to 50",
"Over 50"))) %>%
group_by(Pclass, agecat, Sex) %>%
summarize(N = n(), survivors = sum(Survived)) %>%
mutate(perc_survived = (survivors/N)*100, digits = 5)
titanic_4 <- titanic %>%
select(Survived, Pclass, Age, Sex) %>%
filter(!is.na(Age)) %>%
mutate(agecat = cut(Age, breaks = c(0, 14.99, 50, 150),
include.lowest = TRUE,
labels = c("Under 15", "15 to 50",
"Over 50"))) %>%
group_by(Pclass, agecat, Sex) %>%
summarize(N = n(), survivors = sum(Survived)) %>%
mutate(perc_survived = (survivors/N)*100.000)
titanic %>%
select(Survived, Pclass, Age, Sex) %>%
filter(!is.na(Age)) %>%
mutate(agecat = cut(Age, breaks = c(0, 14.99, 50, 150),
include.lowest = TRUE,
labels = c("Under 15", "15 to 50",
"Over 50"))) %>%
group_by(Pclass, agecat, Sex) %>%
summarize(N = n(), survivors = sum(Survived)) %>%
mutate(perc_survived = (survivors/N)*100.000)
titanic %>%
select(Survived, Pclass, Age, Sex) %>%
filter(!is.na(Age)) %>%
mutate(agecat = cut(Age, breaks = c(0, 14.99, 50, 150),
include.lowest = TRUE,
labels = c("Under 15", "15 to 50",
"Over 50"))) %>%
group_by(Pclass, agecat, Sex) %>%
summarize(N = n(), survivors = sum(Survived)) %>%
mutate(perc_survived = (survivors/N)*100.000) %>%
ungroup()
submit()
shapes <- c("Square", "Circle", "Triangle")
paste("My favorite shape is a", shapes)
paste(shapes, collapse = " ")
head(state.name)
grepl("(i.{2}){3}", "Mississippi")
start_end_vowel <- "^[AEIOU]{1}.+[aeiou]{1}$"
vowel_state <-  grepl(start_end_vowel, state.name)
vowel_state
state.name[vowel_state]
grepl("[Ii]", state.name)
a <- grepl("[Ii]", state.name)
state.name[a]
a <- grepl("[I]", state.name)
state.name[a]
sub("[Ii]", "1", state.name)
gsub("[Ii]", "1", state.name)
two_s <- state.name[grep("ss", state.name)]
two_s
strsplit(two_s, "ss")
strsplit(state.name, "ss")
library(stringr)
state_tbl <- paste(state.name, state.area, state.abb)
state_tbl
str_extract(state_tbl, "[0-9]")
str_extract(state_tbl, "[0-9]+")
head(state.abb)
str_order(state.abb)
str_to_title("table to case")
str_trim("Transpose    to  The   Front ")
str_trim("Transpose   ", "  to",  "The   Front ")
pasted_states <- paste(state.name[1:20], collapse = " ")
cat(str_wrap(pasted_states, width = 80))
cat(str_wrap(pasted_states, width = 40))
library(pryr)
gc()
swirl()
library(swirl)
swirl()
x <- "Hello World!"
x
paste("Square", "Circle", "Triangle" )
paste("Square", "Circle", "Triangle", sep = "+" )
paste0("Square", "Circle", "Triangle" )
shapes <- c("Square", "Circle", "Triangle")
paste("My favorite shape is a", shapes)
paste(shapes, collapse = " ")
nchar("Count Me!")
cases <-  c("CAPS", "low", "Title")
toupper(cases)
tolower(cases)
regular_expression <- "a"
string_to_search <- "Maryland"
grepl(regular_expression, string_to_search)
grepl("ryla", "Maryland")
grepl("Marly", "Maryland")
head(state.name)
grepl(".", "Maryland")
grepl(".", "")
grepl("a.b", c("aaa", "aab", "abb", "acadb"))
grepl("a+", "Maryland")
grepl("x*", "Maryland")
grepl("s{2}", "Mississippi")
grepl("i{2,3}", "Mississippi")
grepl("(iss){2}", "Mississippi")
grepl("\\d", "0123456789")
grepl("\\D", "0123456789")
grepl("[aeiou]", "rhythms")
grepl("\\.", "http://www.jhsph.edu/")
grepl("^a", c("bab", "aab"))
grepl("b$", c("bab", "aab"))
grepl("a|b", c("abc", "bcd", "cde"))
start_end_vowel <- "^[AEIOU]{1}.+[aeiou]{1}$"
vowel_state_lgl <- grepl(start_end_vowel, state.name)
state.name[vowel_state_lgl]
grepl("[Ii]", c("Hawaii", "Illinois", "Kentucky"))
grep("[Ii]", c("Hawaii",
| "Illinois", "Kentucky"))
grep("[Ii]", c("Hawaii", "Illinois", "Kentucky"))
sub("[Ii]", "1", c("Hawaii", "Illinois", "Kentucky"))
gsub("[Ii]", "1", c("Hawaii", "Illinois", "Kentucky"))
two_s <- state.name[grep("ss", state.name)]
two_s
strsplit(two_s, "ss")
str_extract("Camaro Z28", "[0-9]+")
str_order(c("p", "e", "n", "g"))
str_pad("Thai", width = 8, side = "left", pad = "-")
str_to_title(c("CAPS", "low", "Title"))
str_trim(" trim me ")
word("See Spot run.", 2)
install.packages("fivethirtyeight")
data(package = "fivethirtyeight")
data(star-wars)
starwars <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv")
View(starwars)
str(starwars)
summary(starwars)
View(starwars)
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names()
URL<-"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names()
library(fivethirtyeight)
library(tidyverse)
URL<-"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names()
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
install.packages("installr")
library(installr)
updateR()
q()
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
library(fivethirtyeight)
library(tidyverse)
URL<-"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
install <- function(packages){
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages))
install.packages(new.packages, dependencies = TRUE)
sapply(packages, require, character.only = TRUE)
}
# usage
required.packages <- c("ggplot2", "dplyr", "reshape2", "devtools", "tidyverse", "caret","randomForest","knitr",
"stringr","tidyr", "leaflet","ggmap", "lubridate", "readxl", "readr","rvest", "magrittr" )
install(required.packages)
install.packages(c("covr", "Rcpp", "rjson", "sf", "stringi", "tidyr"))
install <- function(packages){
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages))
install.packages(new.packages, dependencies = TRUE)
sapply(packages, require, character.only = TRUE)
}
# usage
required.packages <- c("ggplot2", "dplyr", "reshape2", "devtools", "tidyverse", "caret","randomForest","knitr",
"stringr","tidyr", "leaflet","ggmap", "lubridate", "readxl", "readr","rvest", "magrittr" )
install(required.packages)
library(fivethirtyeight)
install.packages("fivethirtyeight")
library(fivethirtyeight)
library(tidyverse)
URL<-"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
install.packages("janitor")
library(janitor)
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
View(raw_data)
sw_seen_fan <- subset(raw_data[, c(1,2,3,34,35,36,37,38)])
View(sw_seen_fan)
View(sw_seen_fan)
sw_seen_fan <- subset(raw_data[-1, c(1,2,3,34,35,36,37,38)])
str(sw_seen_fan)
names(sw_seen_fan) <- c("id", "seen", "fan", "gender", "age", "income", "edu", "region")
sw_seen_fan[,2:8] = lapply(sw_seen_fan[,2:8], as.factor)
str(sw_seen_fan)
summary(sw_seen_fan)
library(fivethirtyeight)
library(tidyverse)
library(janitor)
URL<-"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
sw_seen_fan <- subset(raw_data[-1, c(1,2,3,34,35,36,37,38)])
names(sw_seen_fan) <- c("id", "seen", "fan", "gender", "age", "income", "edu", "region")
sw_seen_fan[,2:8] = lapply(sw_seen_fan[,2:8], as.factor)
str(sw_seen_fan)
summary(sw_seen_fan)
install.packages("ggmap")
library(ggmap)
world_map <- borders("world", color = "gray50", fill = "gray50")
mp <- ggplot() + world_map
ggplot(sw_seen_fan, aes(x = fan))
ggplot(sw_seen_fan, aes(x = fan)) +
geom_histogram(aes(fill = gender))
ggplot(sw_seen_fan, aes(x = fan), stat = count) +
geom_histogram(aes(fill = gender))
ggplot(sw_seen_fan, aes(x = fan), stat = "count") +
geom_histogram(aes(fill = gender))
ggplot(sw_seen_fan, aes(x = fan)) +
geom_histogram(aes(fill = gender))
ggplot(sw_seen_fan, aes(x = id)) +
geom_histogram(aes(fill = gender))
ggplot(sw_seen_fan, aes(x = fan)) +
geom_bar(aes(fill = gender))
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~fan)
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~fan)
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~seen)
sw_seen_fan <- subset(raw_data[-1, c(1,2,3,34,35,36,37,38)]) %>%
filter("have_you_seen_any_of_the_6_films_in_the_star_wars_franchise" == "Yes")
summary(sw_seen_fan)
sw_seen_fan <- subset(raw_data[-1, c(1,2,3,34,35,36,37,38)]) %>%
filter(have_you_seen_any_of_the_6_films_in_the_star_wars_franchise == "Yes")
summary(sw_seen_fan)
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~seen) +
ggtitle("")
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
ggtitle("Temp")
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~region)
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~region) +
ggtitle("Temp")
) +
ggplot(sw_seen_fan, aes(x = age)) +
geom_bar(aes(fill = gender)) +
facet_grid(~fan) +
ggtitle("Temp")
ggplot(sw_seen_fan, aes(x = fan)) +
geom_bar(aes(fill = gender)) +
facet_grid(~age) +
ggtitle("Temp")
names(sw_seen_fan) <- c("id", "seen", "fan", "gender", "age", "income", "edu", "region")
library(fivethirtyeight)
library(tidyverse)
library(janitor)
library(ggmap)
URL<-"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
raw_data<-read.csv(URL, stringsAsFactors = FALSE,header = TRUE) %>%
clean_names() %>%
mutate(respondent_id=as.character(respondent_id))
sw_seen_fan <- subset(raw_data[-1, c(1,2,3,34,35,36,37,38)]) %>%
filter(have_you_seen_any_of_the_6_films_in_the_star_wars_franchise == "Yes")
names(sw_seen_fan) <- c("id", "seen", "fan", "gender", "age", "income", "edu", "region")
sw_seen_fan[,2:8] = lapply(sw_seen_fan[,2:8], as.factor)
str(sw_seen_fan)
summary(sw_seen_fan)
ggplot(sw_seen_fan, aes(x = fan)) +
geom_bar(aes(fill = gender)) +
facet_grid(~age) +
ggtitle("Temp")
install.packages("alphavantager")
library(alphavantager)
av_api_key("FLV07W0J6TMRJCYV")
av_get(symbol = "BZUN", av_fun = "TIME_SERIES_DAILY_ADJUSTED", outputsize = "full", datatype = "csv")
Baozun <-  av_get(symbol = "BZUN", av_fun = "TIME_SERIES_DAILY_ADJUSTED", outputsize = "full", datatype = "csv")
summary(Baozun)
library(caTools)
split = sample.split(Baozun$adjusted_close, SplitRatio = 0.8)
training_set = subset(Baozun, split == TRUE)
test_set = subset(Baozun, split == FALSE)
regressor = lm(formula = adjusted_close ~ .,
data = training_set)
y_pred = predict(regressor, newdata = test_set)
y_pred
View(test_set)
View(test_set)
summary(regressor)
regressor = lm(formula = adjusted_close ~ timestamp +open + close + high + low+ volume,
data = training_set)
summary(regressor)
y_pred = predict(regressor, newdata = test_set)
y_pred
regressor = lm(formula = adjusted_close ~ timestamp +open + close + high + low+ volume,
data = Baozun)
summary(regressor)
regressor = lm(formula = adjusted_close ~ timestamp +open +low + close + high  + volume,
data = Baozun)
summary(regressor)
regressor = lm(formula = adjusted_close ~ timestamp +low + close + high  + volume,
data = Baozun)
summary(regressor)
regressor = lm(formula = adjusted_close ~ low + close + high  + volume,
data = Baozun)
summary(regressor)
regressor = lm(formula = adjusted_close ~ close + high  + volume,
data = Baozun)
summary(regressor)
regressor = lm(formula = adjusted_close ~ close + high ,
data = Baozun)
summary(regressor)
regressor = lm(formula = adjusted_close ~ close,
data = Baozun)
summary(regressor)
candleChart(Baozun, up.col = "black", dn.col = "red", theme = "white")
install.packages("quantmod")
library(quantmod)
candleChart(Baozun, up.col = "black", dn.col = "red", theme = "white")
regressor = lm(formula = adjusted_close ~ close,
data = Baozun)
summary(regressor)
split = sample.split(Baozun$close, SplitRatio = 0.8)
training_set = subset(Baozun, split == TRUE)
test_set = subset(Baozun, split == FALSE)
regressor = lm(formula = close ~ timestamp + open + high + low + volume,
data = training_set)
summary(regressor)
regressor = lm(formula = close ~ timestamp + open + high + low,
data = training_set)
summary(regressor)
regressor = lm(formula = close ~ open + high + low,
data = training_set)
summary(regressor)
y_pred = predict(regressor, newdata = test_set)
View(test_set)
y_pred
setwd("C:/Users/dsilv/Desktop/Learning/Data Science/ML-model-implementations/K-NN")
iris <- read.csv("Iris.csv")
install.packages("class")
library(class)
any(grepl("<name of your package>", installed.packages()))
any(grepl("class", installed.packages()))
head(iris)
iris <- read.csv("Iris.csv", -1)
head(iris)
iris <- iris[, -1]
head(iris)
library(ggvis)
install.packages("ggvis")
library(ggvis)
iris %>%
ggvis(~PetalLengthCm, ~PetalWidthCm, fill = ~Species) %>%
layer_points()
iris %>%
ggvis(~PetalWidthCm, ~PetalLengthCm, fill = ~Species) %>%
layer_points()
iris %>%
ggvis(~SepalWidthCm, ~SepalLengthCm, fill = ~Species) %>%
layer_points()
iris %>%
ggvis(~PetalWidthCm, ~PetalLengthCm, fill = ~Species) %>%
layer_points()
iris %>%
ggvis(~SepalWidthCm, ~SepalLengthCm, fill = ~Species) %>%
layer_points()
table(iris$Species)
round(prop.table(table(iris$Species)) * 100, digits = 1)
prop.table(table(iris$Species))
prop.table(table(iris$Species)) * 100
irisNorm <- iris
irisNorm[,-5] <- scale(iris[,-5])
summary(irisNorm)
View(irisNorm)
set.seed(1234)
ind <- sample(2, nrow(dataNorm), replace=TRUE, prob=c(0.67,0.33))
trainData <- dataNorm[ind==1,]
testData <- dataNorm[ind==2,]
set.seed(1234)
ind <- sample(2, nrow(dataNorm), replace=TRUE, prob=c(0.67,0.33))
trainData <- irisNorm[ind==1,]
testData <- irisNorm[ind==2,]
set.seed(1234)
ind <- sample(2, nrow(irisNorm), replace=TRUE, prob=c(0.67,0.33))
trainData <- irisNorm[ind==1,]
testData <- irisNorm[ind==2,]
#Create the K-NN model
KnnPred_3 <- knn(trainData[,-5], testData[,-5],
trainData$Species, k=3, prob=TRUE)
KnnPred_2 <- knn(trainData[,-5], testData[,-5],
trainData$Species, k=3, prob=TRUE)
#Confusion matrix
table(testData$Species, KnnPred_2)
table(testData$Species, KnnPred_3)
sum(KnnPred_2==testData$Species)/length(testData$Species)*100
sum(KnnPred_3==testData$Species)/length(testData$Species)*100
accuracy<-mean(trainData$Species==KnnPred_2)
accuracy<-mean(testData$Species==KnnPred_2)
accuracy
KnnPred_3 <- knn(trainData[,-5], testData[,-5],
trainData$Species, k=3, prob=TRUE)
KnnPred_3 <- knn(trainData[,-5], testData[,-5],
trainData$Species, k=3, prob=TRUE)
#Confusion matrix
table(testData$Species, KnnPred_2)
sum(KnnPred_3==testData$Species)/length(testData$Species)*100
#OR
accuracy<-mean(testData$Species==KnnPred_3)
accuracy
KnnPred_6 <- knn(trainData[,-5], testData[,-5],
trainData$Species, k=6, prob=TRUE)
#Confusion matrix
table(testData$Species, KnnPred_6)
sum(KnnPred_3==testData$Species)/length(testData$Species)*100
#OR
accuracy<-mean(testData$Species==KnnPred_6)
accuracy
setwd("C:/Users/dsilv/Desktop/Learning/Data Science/ML-model-implementations/K-NN")
library(class)
library(ggvis)
iris <- read.csv("Iris.csv", -1)
iris <- iris[, -1]
iris %>%
ggvis(~PetalWidthCm, ~PetalLengthCm, fill = ~Species) %>%
layer_points()
iris %>%
ggvis(~SepalWidthCm, ~SepalLengthCm, fill = ~Species) %>%
layer_points()
table(iris$Species)
prop.table(table(iris$Species)) * 100
#Normalize iris data
irisNorm <- iris
irisNorm[,-5] <- scale(iris[,-5])
summary(irisNorm)
#Create training and test data
set.seed(1234)
ind <- sample(2, nrow(irisNorm), replace=TRUE, prob=c(0.7,0.3))
trainData <- irisNorm[ind==1,]
testData <- irisNorm[ind==2,]
#Create the K-NN model
KnnPred_7 <- knn(trainData[,-5], testData[,-5],
trainData$Species, k=7, prob=TRUE)
#Confusion matrix
table(testData$Species, KnnPred_7)
sum(KnnPred_7==testData$Species)/length(testData$Species)*100
#OR
accuracy<-mean(testData$Species==KnnPred_7)
accuracy
iris %>% ggplot(aes(PetalLengthCm, PetalWidthCm, color = Species)) + geom_jitter() +
scale_color_manual(values=c("mediumpurple3", "violetred3", "darkturquoise"))
library(ggplot2)
iris %>% ggplot(aes(PetalLengthCm, PetalWidthCm, color = Species)) + geom_jitter() +
scale_color_manual(values=c("mediumpurple3", "violetred3", "darkturquoise"))
setwd("C:/Users/dsilv/Desktop/Learning/Data Science/Data-Analysis-Projects-In-R/Data Scientist Survey")
knitr::opts_chunk$set(echo = TRUE)
library(tm)
setwd("C:/Users/dsilv/Desktop/Learning/Data Science/Data-Analysis-Projects-In-R/Data Scientist Survey")
library(tidyverse)
library(stringr)
library(tm)
setwd("C:/Users/dsilv/Desktop/Learning/Data Science/Data-Analysis-Projects-In-R/Data Scientist Survey")
library(tidyverse)
library(stringr)
library(tm)
knitr::opts_chunk$set(echo = TRUE)
plot(pressure)
# Import multiple choice responses
rawMCdata <- read.csv('multipleChoiceResponses.csv', stringsAsFactors = TRUE, header = TRUE)
# Import freeform responses
rawFFRdata <- read.csv('freeformResponses.csv', stringsAsFactors = FALSE, header = TRUE)
# Import questions asked
schema <- read.csv('schema.csv', stringsAsFactors = FALSE, header = TRUE)
# Import currency conversion rates
conversionRates <- read.csv('conversionRates.csv', header = TRUE)
# Import multiple choice responses
rawMCdata <- read.csv('multipleChoiceResponses.csv', stringsAsFactors = TRUE, header = TRUE)
# Import freeform responses
rawFFRdata <- read.csv('freeformResponses.csv', stringsAsFactors = FALSE, header = TRUE)
# Import questions asked
schema <- read.csv('schema.csv', stringsAsFactors = FALSE, header = TRUE)
# Import currency conversion rates
conversionRates <- read.csv('conversionRates.csv', header = TRUE)
